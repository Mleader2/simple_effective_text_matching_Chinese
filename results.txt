# 闲聊的匹配模型
#echo "python train.py" ${masker_ranker} "GPU:" ${gpu} "chat_courpus_log.txt"
CUDA_VISIBLE_DEVICES=${gpu} nohup python -u train.py ${config_json} ${host_name} > chat_courpus_log.txt 2>&1 &
tail -f chat_courpus_log.txt
# python train.py ${config_json} ${host_name}

#blocks=1,  enc_layers=2  batch_size=128 lr=0.001, prediction':'simple'    'fusion': 'full',  maxlen=20
# experiment_times=5/5, ave_test_score=0.802228, max_test_score=0.808940
# 如果只用lcqmc  experiment_times=5/5, ave_test_score=0.834672, max_test_score=0.841840  说明BQcorpus难度大   inference_time: 0.009

#batch_size，lr增加50%
#blocks=1,  enc_layers=2  batch_size=384   lr=0.001, prediction':'simple'    'fusion': 'full',  maxlen=20
#experiment_times=5/5, ave_test_score=0.795793, max_test_score=0.804216

# 降低学习率  准确率降低到75%-76%
#blocks=1,  enc_layers=2  batch_size=384   lr=0.0001, prediction':'simple'    'fusion': 'full',  maxlen=20

# 提高学习率 lr: 0.005 较好
#blocks=1,  enc_layers=2  batch_size=384   lr=0.005, prediction':'simple'    'fusion': 'full',  maxlen=20
#experiment_times=5/5, ave_test_score=0.803851, max_test_score=0.815180

#block=2 enc_layers=2 inference_time=19.337797 ms （慢了一倍） 81.7%  acc提高1%
#04/08/2020 10:12:37 Training time: 0:15:57.
#[train.py:29]  experiment_times=5/5, ave_test_score=0.817319, max_test_score=0.825341
#stats: {'inference_time': 1.1077707639851133, 'auc': 0.8672013396287949, 'f1': 0.786558313200088, 'acc': 0.7834477226134237}  微调后cpu测试

#block=2 enc_layers=1 inference_time=17.902684 ms （慢了接近一倍） 和enc_layers=2差不多
# experiment_times=5/5, ave_test_score=0.817765, max_test_score=0.828193
#experiment_times=5/5, ave_test_score=0.815269, max_test_score=0.821419
#GPU上测试  [demo.py:81]  stats: {'inference_time': 0.13252100063439243, 'auc': 0.9065379393588313, 'f1': 0.8247079924756113, 'acc': 0.8214190213031465}

# 接下来想要改成计算第一层block时enc_layers=2，将text1和若干text2拼接起来处理,后面enc_layers=1按照正常逻辑处理
# GPU上训练一个epoch的时间从1.97变成2.00  CPU上推理延迟降低从28.250353ms到22.8ms
#block=2 enc_layers=1 较好
#[train.py:30]  experiment_times=5/5, ave_test_score=0.820127, max_test_score=0.824048
# run again  experiment_times=5/5, ave_test_score=0.811712, max_test_score=0.815848
# [train.py:29]  experiment_times=1/5, ave_test_score=0.801765, max_test_score=0.801765
inference_time ms
batchsize    30          50
优化前 ms     27.6       39.6
优化后 ms     25.4       36.1


#block=2 enc_layers=2 block2_layer2_full 变差了
#[train.py:29]  experiment_times=5/5, ave_test_score=0.805981, max_test_score=0.810901   Training time: 0:09:01.
#experiment_times=5/5, ave_test_score=0.802986, max_test_score=0.813620  Training time: 0:08:04.
#experiment_times=5/5, ave_test_score=0.808842, max_test_score=0.814377  Training time: 0:14:00.

inference_time ms
batchsize    30          50
优化前 ms     26.45        45.4
优化后 ms     24.3       36.5



# 试试symmetric   block2_layer2_symmetric
#experiment_times=5/5, ave_test_score=0.798503, max_test_score=0.812550
inference_time=37.586354 ms   inference_time=38.655164 ms  inference_time=38.126519 ms
inference_time ms
batchsize    30          50
优化前 ms     26.45        45.4
优化后 ms     23.8       37.5

prediction:simple block2_layer2_simple
experiment_times=5/5, best_experiment_times=4, ave_test_score=0.799465, max_test_score=0.808049
inference_time ms
batchsize    30          50     100
优化前 ms     18.2      29.0       84.9
优化后 ms     16.7       23.9      77.4

block=1 layer=2 hidden_size=400 prediction:full




inference_time ms  block=1 layer=2  hidden=200
#[train.py:30]  experiment_times=5/5, ave_test_score=0.820127, max_test_score=0.824048
batchsize    30          50
优化前 ms     17.39      29.0
优化后 ms     15.4       23.7

inference_time ms  block=1 layer=2  hidden=400  显存不足  CPU推理也慢了不少
04/09/2020 04:54:56 best dev score 0.8113468223549336 at step 6336 (epoch 8).
04/09/2020 04:54:56 best eval stats [loss: 0.4403 inference_time: 42.6206 auc: 0.9068 f1: 0.8234 acc: 0.8113 cost_time: 15.1283]
[train.py:37]  experiment_times=5/5, best_experiment_times=1, ave_test_score=0.804599, max_test_score=0.811347
batchsize    30          50
优化前 ms     41.68      67.31
优化后 ms     36.1       59.2

inference_time ms  block=1 layer=2  hidden=300  房山  较好
04/09/2020 06:37:14 Training time: 0:10:41.
[train.py:37]  experiment_times=5/5, best_experiment_times=2, ave_test_score=0.809635, max_test_score=0.822845
[demo.py:89]  stats: {'inference_time': 0.9978332348670623, 'auc': 0.9068339527862, 'f1': 0.8272114757661378, 'acc': 0.8228451733666102}
[demo.py:38]  infer_flag: True ,predict_batchsize= 30
[demo.py:61]  inference_time1=24.401224 ms, inference_time=23.994634 ms
batchsize    30          50
优化前 ms     27.4       44.5
优化后 ms     24.0       37.8

inference_time ms  block=1 layer=3  hidden=400  本地
04/09/2020 05:54:51 trainable params: 4,127,205
[train.py:38]  experiment_times=5/5, best_experiment_times=4, ave_test_score=0.796657, max_test_score=0.810767
[train.py:47]  eval_score_list: [0.7923611730100723, 0.789954541402977, 0.7916480969783403, 0.798556021035743, 0.8107674480791515] 4
[demo.py:38]  infer_flag: True ,predict_batchsize= 30
[demo.py:61]  inference_time1=39.286757 ms, inference_time=38.814596 ms
[demo.py:61]  inference_time1=42.803967 ms, inference_time=41.222696 ms
[demo.py:38]  infer_flag: True ,predict_batchsize= 50
[demo.py:61]  inference_time1=60.126448 ms, inference_time=60.603931 ms
[demo.py:61]  inference_time1=65.088594 ms, inference_time=62.463285 ms

[demo.py:38]  infer_flag: False ,predict_batchsize= 30
[demo.py:61]  inference_time1=49.417663 ms, inference_time=47.830650 ms
[demo.py:61]  inference_time1=53.199601 ms, inference_time=47.482363 ms
[demo.py:38]  infer_flag: False ,predict_batchsize= 50
[demo.py:61]  inference_time1=69.589388 ms, inference_time=69.067456 ms
[demo.py:61]  inference_time1=69.666946 ms, inference_time=69.120533 ms
batchsize    30          50
优化前 ms     47.5       69.1
优化后 ms     38.8       60.6


inference_time ms  block=1 layer=3  hidden=300  房山
04/10/2020 09:18:21 Training time: 0:07:14.
[train.py:37]  experiment_times=5/5, best_experiment_times=3, ave_test_score=0.801569, max_test_score=0.813441



#block=2 enc_layers=2 block=2 layer=2
experiment_times=5/5, ave_test_score=0.808842, max_test_score=0.814377  Training time: 0:14:00.
batchsize    30          50     100
优化前 ms     18.2      29.0       84.9
优化后 ms     16.7       23.9      77.4




[demo.py:38]  infer_flag: False ,predict_batchsize= 100
[demo.py:59]  inference_time=41.652980 ms

[demo.py:38]  infer_flag: True ,predict_batchsize= 100
[demo.py:59]  inference_time=36.435516 ms

[demo.py:38]  infer_flag: True ,predict_batchsize= 100
[demo.py:59]  inference_time=49.93 ms
[demo.py:38]  infer_flag: False ,predict_batchsize= 100
[demo.py:59]  inference_time=53.980533 ms

[demo.py:38]  infer_flag: True ,predict_batchsize= 100
[demo.py:61]  inference_time1=54.388463 ms, inference_time=51.567709 ms
[demo.py:38]  infer_flag: True ,predict_batchsize= 100
[demo.py:61]  inference_time1=55.565810 ms, inference_time=56.355667 ms
[demo.py:38]  infer_flag: True ,predict_batchsize= 100
[demo.py:61]  inference_time1=52.851069 ms, inference_time=53.652096 ms
[demo.py:38]  infer_flag: True ,predict_batchsize= 100
[demo.py:61]  inference_time1=51.090300 ms, inference_time=52.383467 ms
[demo.py:38]  infer_flag: True ,predict_batchsize= 100
[demo.py:61]  inference_time1=49.942648 ms, inference_time=49.684069 ms


[demo.py:38]  infer_flag: False ,predict_batchsize= 100
[demo.py:61]  inference_time1=61.680663 ms, inference_time=56.739576 ms
[demo.py:38]  infer_flag: False ,predict_batchsize= 100
[demo.py:61]  inference_time1=53.338659 ms, inference_time=52.637645 ms
[demo.py:38]  infer_flag: False ,predict_batchsize= 100
[demo.py:61]  inference_time1=53.442144 ms, inference_time=52.512710 ms

[demo.py:38]  infer_flag: False ,predict_batchsize= 30
[demo.py:61]  inference_time1=17.575490 ms, inference_time=17.016582 ms
[demo.py:38]  infer_flag: False ,predict_batchsize= 30
[demo.py:61]  inference_time1=20.082664 ms, inference_time=19.406968 ms

[demo.py:38]  infer_flag: True ,predict_batchsize= 30
[demo.py:61]  inference_time1=18.918300 ms, inference_time=17.164890 ms
[demo.py:38]  infer_flag: True ,predict_batchsize= 30
[demo.py:61]  inference_time1=19.240046 ms, inference_time=16.757571 ms



########   python demo.py configs/main.json5  cloudminds  benchmark-0
########   python demo.py configs/main.json5  wzk  benchmark-0

##   python evaluate.py $model_path $data_file



#04/08/2020 02:24:09 train loss: 0.4535 lr: 0.0050 gnorm: 0.5409 clip: 0
#04/08/2020 02:24:09 valid loss: 0.5331 inference_time: 471.0568 auc: 0.8262 f1: 0.7573 acc: 0.7329 cost_time: 5.2296 [NEW BEST]
#04/08/2020 02:26:46 > epoch 1 updates 300 loss: 0.3810 lr: 0.0050 gnorm: 0.1493
#04/08/2020 02:26:46 train loss: 0.3905 lr: 0.0050 gnorm: 0.2620 clip: 0
#04/08/2020 02:26:46 valid loss: 0.5112 inference_time: 469.1583 auc: 0.8408 f1: 0.7617 acc: 0.7501 cost_time: 7.8512 [NEW BEST]
#04/08/2020 02:29:26 > epoch 1 updates 400 loss: 0.3619 lr: 0.0050 gnorm: 0.2790
#04/08/2020 02:29:26 train loss: 0.3901 lr: 0.0050 gnorm: 0.3245 clip: 0
#04/08/2020 02:29:26 valid loss: 0.4931 inference_time: 480.2539 auc: 0.8442 f1: 0.7581 acc: 0.7555 cost_time: 10.5080 [NEW BEST]
#04/08/2020 02:32:07 > epoch 1 updates 500 loss: 0.4362 lr: 0.0050 gnorm: 0.2289
#04/08/2020 02:32:07 train loss: 0.4072 lr: 0.0050 gnorm: 0.2145 clip: 0
#04/08/2020 02:32:07 valid loss: 0.4736 inference_time: 477.7828 auc: 0.8575 f1: 0.7746 acc: 0.7679 cost_time: 13.2010 [NEW BEST]
#04/08/2020 02:34:46 > epoch 1 updates 600 loss: 0.3635 lr: 0.0050 gnorm: 0.1544
#04/08/2020 02:34:46 train loss: 0.3936 lr: 0.0050 gnorm: 0.1810 clip: 0
#04/08/2020 02:34:46 valid loss: 0.4765 inference_time: 479.9553 auc: 0.8611 f1: 0.7808 acc: 0.7721 cost_time: 15.8459 [NEW BEST]
#04/08/2020 02:37:29 > epoch 1 updates 700 loss: 0.3537 lr: 0.0047 gnorm: 0.1494
#04/08/2020 02:37:29 train loss: 0.3426 lr: 0.0049 gnorm: 0.1570 clip: 0
#04/08/2020 02:37:29 valid loss: 0.4909 inference_time: 483.9887 auc: 0.8640 f1: 0.7811 acc: 0.7728 cost_time: 18.5735 [NEW BEST]
#04/08/2020 02:37:49 > epoch 1 updates 750 loss: 0.3448 lr: 0.0047 gnorm: 0.2319


#04/08/2020 02:51:27 valid loss: 0.5831 inference_time: 472.1677 auc: 0.8149 f1: 0.7417 acc: 0.7283 cost_time: 5.4799 [NEW BEST]
#04/08/2020 02:54:14 > epoch 1 updates 300 loss: 0.3616 lr: 0.0050 gnorm: 0.1110
#04/08/2020 02:54:14 train loss: 0.3585 lr: 0.0050 gnorm: 0.1188 clip: 0
#04/08/2020 02:54:14 valid loss: 0.5229 inference_time: 515.2642 auc: 0.8297 f1: 0.7479 acc: 0.7445 cost_time: 8.2597 [NEW BEST]
#04/08/2020 02:56:57 > epoch 1 updates 400 loss: 0.3844 lr: 0.0050 gnorm: 0.0967
#04/08/2020 02:56:57 train loss: 0.3979 lr: 0.0050 gnorm: 0.1573 clip: 0
#04/08/2020 02:56:57 valid loss: 0.5151 inference_time: 472.3220 auc: 0.8452 f1: 0.7626 acc: 0.7564 cost_time: 10.9893 [NEW BEST]
#04/08/2020 02:59:48 > epoch 1 updates 500 loss: 0.3738 lr: 0.0050 gnorm: 0.0893
#04/08/2020 02:59:48 train loss: 0.3645 lr: 0.0050 gnorm: 0.1034 clip: 0
#04/08/2020 02:59:48 valid loss: 0.4932 inference_time: 508.3649 auc: 0.8555 f1: 0.7756 acc: 0.7612 cost_time: 13.8365 [NEW BEST]
#04/08/2020 03:02:37 > epoch 1 updates 600 loss: 0.3621 lr: 0.0050 gnorm: 0.1114
#04/08/2020 03:02:37 train loss: 0.3540 lr: 0.0050 gnorm: 0.1171 clip: 0
#04/08/2020 03:02:37 valid loss: 0.4740 inference_time: 479.0968 auc: 0.8608 f1: 0.7757 acc: 0.7690 cost_time: 16.6454 [NEW BEST]
#04/08/2020 03:05:26 > epoch 1 updates 700 loss: 0.2937 lr: 0.0047 gnorm: 0.1188
#04/08/2020 03:05:26 train loss: 0.3258 lr: 0.0049 gnorm: 0.1185 clip: 0
#04/08/2020 03:05:26 valid loss: 0.4598 inference_time: 475.4500 auc: 0.8695 f1: 0.7840 acc: 0.7809 cost_time: 19.4641 [NEW BEST]
#04/08/2020 03:07:11 > epoch 1 updates 750 loss: 0.3455 lr: 0.0047 gnorm: 0.0845
#04/08/2020 03:07:11 train loss: 0.3455 lr: 0.0047 gnorm: 0.0845 clip: 0
#04/08/2020 03:07:11 valid loss: 0.4817 inference_time: 507.1521 auc: 0.8635 f1: 0.7819 acc: 0.7684 cost_time: 21.2226 [BEST: 0.7809]
